> åŸæ–‡é“¾æ¥: https://www.freecodecamp.org/news/implement-naive-bayes-with-rust/
>
> ç¿»è¯‘ï¼š[Ch3nYe](https://github.com/Ch3nYe)
>
> é€‰é¢˜ï¼š[Ch3nYe](https://github.com/Ch3nYe)
>
> æœ¬æ–‡ç”± [Rustt](https://Rustt.org) ç¿»è¯‘ï¼Œ[RustCn](https://hirust.cn) è£èª‰æ¨å‡º

# å¦‚ä½•ç”¨ Rust å®ç°æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨



æˆ‘æƒ³ç²¾è¿›æˆ‘çš„ Rust ç¼–ç¨‹æŠ€èƒ½ï¼ŒåŒæ—¶ä¹Ÿå¸®åŠ©ä½ ç£¨ç»ƒæŠ€èƒ½ã€‚æ‰€ä»¥æˆ‘å†³å®šå†™ä¸€ç³»åˆ—å…³äº Rust ç¼–ç¨‹è¯­è¨€çš„æ–‡ç« ã€‚



åœ¨å®é™…ä½¿ç”¨ Rust å†™ä¸œè¥¿çš„æ—¶å€™ï¼Œæˆ‘èƒ½å­¦åˆ°å¾ˆå¹¿æ³›çš„æŠ€æœ¯æ¦‚å¿µã€‚åœ¨æœ¬æœŸä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Rust å®ç°æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ã€‚



æ‚¨å¯èƒ½ä¼šåœ¨æœ¬æ–‡ä¸­é‡åˆ°ä¸€äº›ä¸ç†Ÿæ‚‰çš„æœ¯è¯­æˆ–æ¦‚å¿µã€‚ä¸è¦æ°”é¦ï¼Œå¦‚æœä½ æœ‰æ—¶é—´å¯ä»¥è‡ªè¡Œå­¦ä¹ ï¼Œä½†æ— è®ºå¦‚ä½•ï¼Œå¸Œæœ›ä½ ä¸è¦åç¦»æœ¬æ–‡çš„ä¸»è¦æ€è·¯ã€‚



## ä»€ä¹ˆæ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨



æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æ˜¯ä¸€ä¸ªåŸºäºè´å¶æ–¯ç†è®ºçš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚[è´å¶æ–¯ç†è®º](https://greenteapress.com/wp/think-bayes/)æ˜¯ä¸€ç§é€šè¿‡ç»™å®šä¸€äº›æ•°æ® D ï¼Œæ¥æ›´æ–°ä¸€ä¸ªå‡è®¾ H çš„æ¦‚ç‡çš„æ–¹æ³•ã€‚



æ•°å­¦è¡¨è¾¾ä¸ºï¼š


$$
P(H \mid D)=\frac{P(D \mid H) P(H)}{P(D)}
$$



$P(H|D)$ æ˜¯ç»™å‡ºæ•°æ® D å‡è®¾ H æˆç«‹çš„æ¦‚ç‡ã€‚



å¦‚æœæˆ‘ä»¬ç»Ÿè®¡æ›´å¤šæ•°æ®ï¼Œå°±å¯ä»¥æ ¹æ®è¿™äº›æ•°æ®æ›´æ–°$P(H|D)$ ã€‚



æœ´ç´ è´å¶æ–¯æ¨¡å‹åŸºäºä¸€ä¸ªå¤§å‡è®¾ï¼šæ•°æ®é›†ä¸­æ˜¯å¦å­˜åœ¨æ•°æ®ç‚¹ä¸è¯¥æ•°æ®é›†ä¸­å·²ç»å­˜åœ¨çš„æ•°æ®æ— å…³ï¼ˆ[å‚è€ƒ](https://www.oreilly.com/library/view/data-science-from/9781492041122/)ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯æ¡æ•°æ®ä¹‹é—´ç›¸äº’ç‹¬ç«‹ã€‚



æ˜¾ç„¶ï¼Œè¿™ä¸ªå‡è®¾æ˜¯æ¯”è¾ƒå¼±çš„ï¼Œç°å®ä¸­éš¾ä»¥å®Œå…¨æˆç«‹ã€‚ä½†å®ƒä»ç„¶å¾ˆæœ‰ç”¨ï¼Œå®ƒå…è®¸æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç”¨èµ·æ¥è¿˜ä¸é”™çš„çš„é«˜æ•ˆåˆ†ç±»å™¨ï¼ˆ[å‚è€ƒ](https://probml.github.io/pml-book/book0.html)ï¼‰ã€‚



å¯¹æœ´ç´ è´å¶æ–¯çš„æè¿°å°±åœåœ¨è¿™é‡Œï¼Œæœ¬æ–‡çš„é‡ç‚¹æ˜¯ç»ƒä¹  Rust ã€‚



å¦‚æœæ‚¨æƒ³äº†è§£æœ‰å…³è¯¥ç®—æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè¿™é‡Œæœ‰ä¸€äº›èµ„æºï¼š

- Josh Starmer çš„[è§†é¢‘](https://www.youtube.com/watch?v=O2L2Uv9pdDA&t=657s)è®²è§£éå¸¸å¥½.
- Joel Grus åœ¨ã€Š*[Data Science from Scratch](https://learning.oreilly.com/library/view/data-science-from/9781492041122/)*ã€‹è¿™æœ¬ä¹¦ä¸­å…³äºè´å¶æ–¯ä¸€èŠ‚çš„æè¿°æ˜¯æœ¬æ–‡å®ç°çš„å¯å‘ã€‚
- å¦‚æœä½ æ›´å–œæ¬¢æ•°å­¦çš„å½¢å¼åŒ–å®šä¹‰,Â [try section 6.6.3 ofÂ *The Elements of Statisical Learning](https://hastie.su.domains/Papers/ESLII.pdf).*
- ä¸€ç¯‡å…³äºç®—æ³•å·¥ä½œåŸç†çš„æœ‰ç”¨[æ–‡ç« ](https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/)



æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„å…¸å‹åº”ç”¨æ˜¯**åƒåœ¾é‚®ä»¶åˆ†ç±»å™¨**ã€‚è¿™å°±æ˜¯æˆ‘ä»¬è¦å®ç°çš„ä¸œè¥¿ã€‚ä»£ç åœ¨è¿™ï¼š

[https://github.com/josht-jpg/shaking-off-the-rust](https://github.com/josht-jpg/shaking-off-the-rust)



æˆ‘ä»¬ä»ä½¿ç”¨ Cargo åˆ›å»ºä¸€ä¸ªæ–°çš„åº“å¼€å§‹ï¼š

```bash
cargo new naive_bayes --lib
cd naive_bayes
```



## Tokenization in Rust



æˆ‘ä»¬çš„åˆ†ç±»å™¨ä¼šå°†é‚®ä»¶æ¶ˆæ¯å†…å®¹ä½œä¸ºè¾“å…¥å¹¶è¿”å›å…¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶çš„åˆ†ç±»ã€‚



ä¸ºäº†å¤„ç†æˆ‘ä»¬æ”¶åˆ°çš„æ¶ˆæ¯ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å…¶è¿›è¡Œtokenizeï¼ˆåˆ†è¯ï¼‰ã€‚æˆ‘ä»¬çš„è¯æ±‡è¡¨å°†æ˜¯ä¸€å †å°å†™çš„å•è¯ï¼Œå¿½ç•¥é¡ºåºå’Œé‡å¤å•è¯ã€‚Rust çš„ [`std::collections::HashSet`](https://doc.rust-lang.org/std/collections/struct.HashSet.html) ç»“æ„æ­£åˆé€‚æ¥å®ç°è¯æ±‡è¡¨ã€‚



æˆ‘ä»¬å°†ç¼–å†™åˆ†è¯çš„å‡½æ•°å°†éœ€è¦ä½¿ç”¨ [regex](https://docs.rs/regex/latest/regex/) crateã€‚ç¡®ä¿åœ¨ Cargo.toml æ–‡ä»¶ä¸­åŒ…å«ä»¥ä¸‹ä¾èµ–é¡¹ï¼š

```yaml
[dependencies]
regex = "^1.5.4"
```



`tokenize` åˆ†è¯å‡½æ•°ï¼š

```rust
// lib.rs

// We'll need HashMap later
use std::collections::{HashMap, HashSet};

extern crate regex;
use regex::Regex;

pub fn tokenize(lower_case_text: &str) -> HashSet<&str> {
    Regex::new(r"[a-z0-9']+")
        .unwrap()
        .find_iter(lower_case_text)
        .map(|mat| mat.as_str())
        .collect()
}
```



æ­¤å‡½æ•°ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€æœ‰æ•°å­—å’Œå°å†™å­—æ¯ã€‚æ¯å½“æˆ‘ä»¬é‡åˆ°ä¸åŒç±»å‹çš„ç¬¦å·ï¼ˆé€šå¸¸æ˜¯ç©ºæ ¼æˆ–æ ‡ç‚¹ç¬¦å·ï¼‰æ—¶ï¼Œæˆ‘ä»¬å°±ä¼šæ‹†åˆ†è¾“å…¥å¹¶å°†è‡ªä¸Šæ¬¡æ‹†åˆ†åé‡åˆ°çš„æ‰€æœ‰æ•°å­—å’Œå­—æ¯ç»„åˆåœ¨ä¸€èµ·ï¼ˆä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://rust-lang-nursery.github.io/rust-cookbook/text/regex.html)é˜…è¯»æœ‰å…³ Rust æ­£åˆ™è¡¨è¾¾å¼çš„æ›´å¤šå†…å®¹ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æ­£åœ¨è¯†åˆ«å’Œåˆ†å‰²è¾“å…¥æ–‡æœ¬ä¸­çš„å•è¯ã€‚



## æ„é€ ç»“æ„ä½“



ä½¿ç”¨ `struct` æ¥è¡¨ç¤ºæ¶ˆæ¯æ˜¯å¾ˆå¥½çš„æ–¹æ³•ã€‚`struct` å°†åŒ…å«æ¶ˆæ¯æ–‡æœ¬çš„*å­—ç¬¦ä¸²åˆ‡ç‰‡*ï¼Œä»¥åŠæŒ‡ç¤ºæ¶ˆæ¯æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶çš„å¸ƒå°”å€¼ï¼š

```rust
pub struct Message<'a> {
    pub text: &'a str,
    pub is_spam: bool,
}
```

`'a` æ˜¯å£°æ˜å‘¨æœŸæ³¨é‡Šã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰ç”Ÿå‘½å‘¨æœŸï¼Œæˆ‘æ¨èä½ é˜…è¯» [section 10.3 of The Rust Programming Language Book](https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html) ã€‚



## ä»€ä¹ˆæ˜¯æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼Ÿ



å‡è®¾â€”â€”åœ¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ä¸­â€”â€”å•è¯ `fubar` å‡ºç°åœ¨ä¸€äº›éåƒåœ¾é‚®ä»¶ä¸­ï¼Œä½†æ²¡æœ‰å‡ºç°åœ¨ä»»ä½•åƒåœ¾é‚®ä»¶ä¸­ã€‚æ­¤æ—¶ï¼Œæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æŠŠä»»ä½•åŒ…å«å•è¯ `fubar`ï¼ˆ[å‚è€ƒ](https://www.youtube.com/watch?v=nt63k3bfXS0)ï¼‰çš„æ¶ˆæ¯è®¤å®šä¸ºéåƒåœ¾é‚®ä»¶ï¼Œä¹Ÿå°±æ˜¯è¯´è¯¥æ¶ˆæ¯æ˜¯åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡ä¸º 0 ã€‚



æ˜¾ç„¶ï¼Œä»…ä»…å› ä¸ºå®ƒè¿˜æ²¡æœ‰å‘ç”Ÿå°±ç»™å®ƒåˆ†é… 0 çš„æ¦‚ç‡æ˜¯ä¸åˆé€‚çš„ã€‚



åŠ å…¥æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å°±æ˜¯ç”¨æ¥è§£å†³è¿™ä¸ªé—®é¢˜çš„ï¼Œå°†ä¸€ä¸ªå¸¸æ•° $\alpha$ åŠ åœ¨æ¯ä¸ªå•è¯å‡ºç°çš„æ¬¡æ•°ç»Ÿè®¡ä¸Šã€‚æˆ‘ä»¬æ¥è§‚å¯Ÿä¸€ä¸‹æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å¸¸æ•°åŠ å…¥å‰åï¼Œåœ¨åƒåœ¾é‚®ä»¶ä¸­çœ‹åˆ°å•è¯ *w* çš„æ¦‚ç‡ä¸ºï¼š

$$
P(w|S) = \frac{number\ of\ spam\ messages\ containing\ w}{total\ number\ of\ spams}
$$



ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘åå°±æ˜¯ï¼š
$$
P(w|S) = \frac{\alpha + number\ of\ spam\ messages\ containing\ w}{2\alpha + total\ number\ of\ spams}
$$



å…·ä½“åˆ°åˆ†ç±»å™¨ç»“æ„ä½“å°±æ˜¯ï¼š

```rust
pub struct NaiveBayesClassifier {
    pub alpha: f64,
    pub tokens: HashSet<String>,
    pub token_ham_counts: HashMap<String, i32>,
    pub token_spam_counts: HashMap<String, i32>,
    pub spam_messages_count: i32,
    pub ham_messages_count: i32,
}
```

`NaiveBayesClassifier` çš„å®ç°å°†å›´ç»•ä¸€ä¸ª `train` æ–¹æ³•å’Œä¸€ä¸ª `predict` æ–¹æ³•ã€‚



## å¦‚ä½•è®­ç»ƒåˆ†ç±»å™¨



`train` æ–¹æ³•å°†æ¥æ”¶å¤šä¸ª `Message` ï¼Œå¹¶å¾ªç¯å¯¹æ¯ä¸ª `Message` è¿›è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

- æ£€æŸ¥é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶å¹¶ç›¸åº”åœ°æ›´æ–° `spam_messages_count` æˆ– `ham_messages_count`ã€‚æˆ‘ä»¬ä¸ºæ­¤åˆ›å»ºè¾…åŠ©å‡½æ•° `increment_message_classifications_count` ã€‚
- ä½¿ç”¨ `tokenize` å‡½æ•°å°†æ¶ˆæ¯åˆ†è¯ã€‚
- éå†æ¶ˆæ¯ä¸­çš„æ¯ä¸ªå•è¯ï¼Œç„¶åï¼š
- å°†å•è¯æ’å…¥è¯æ±‡è¡¨ `HashSet` ï¼Œç„¶åæ›´æ–°`token_spam_counts` æˆ– `token_ham_counts` ã€‚æˆ‘ä»¬ä¸ºæ­¤åˆ›å»ºè¾…åŠ©å‡½æ•° `increment_token_count`



ä¸‹é¢æ˜¯ `train` æ–¹æ³•çš„ä¼ªä»£ç ã€‚å¦‚æœä½ æ„¿æ„ï¼Œå°è¯•å°†ä¼ªä»£ç è½¬æ¢ä¸º Rustï¼Œç„¶åå†æŸ¥çœ‹ä¸‹é¢çš„å®ç°ã€‚


```rust
implementation block for NaiveBayesClassifier {

	train(self, messages) {
		for each message in messages {
			self.increment_message_classifications_count(message)
			
			lowercase_text = to_lowercase(message.text)
			for each token in tokenize(lowercase_text) {
				self.tokens.insert(tokens)
				self.increment_token_count(token, message.is_spam)
			}			
		}
	}

	increment_message_classifications_count(self, message) {
		if message.is_spam {
			self.spam_messages_count = self.spam_messages_count + 1
		} else {
			self.ham_messages_count = self.ham_messages_count + 1
		}
	}

	increment_token_count(&mut self, token, is_spam) {
		if token is not a key of self.token_spam_counts {
			insert record with key=token and value=0 into self.token_spam_counts
		}

		if token is not a key of self.token_ham_counts {
			insert record with key=token and value=0 into self.token_ham_counts
		}

		if is_spam {
			self.token_spam_counts[token] = self.token_spam_counts[token] + 1
		} else {
			self.token_ham_counts[token] = self.token_ham_counts[token] + 1
		}
	}

}
```



ä¸‹é¢æ˜¯ Rust çš„å®ç°ï¼š

```rust
impl NaiveBayesClassifier {
    pub fn train(&mut self, messages: &[Message]) {
        for message in messages.iter() {
            self.increment_message_classifications_count(message);
            for token in tokenize(&message.text.to_lowercase()) {
                self.tokens.insert(token.to_string());
                self.increment_token_count(token, message.is_spam)
            }
        }
    }

    fn increment_message_classifications_count(&mut self, message: &Message) {
        if message.is_spam {
            self.spam_messages_count += 1;
        } else {
            self.ham_messages_count += 1;
        }
    }

    fn increment_token_count(&mut self, token: &str, is_spam: bool) {
        if !self.token_spam_counts.contains_key(token) {
            self.token_spam_counts.insert(token.to_string(), 0);
        }

        if !self.token_ham_counts.contains_key(token) {
            self.token_ham_counts.insert(token.to_string(), 0);
        }

        if is_spam {
            self.increment_spam_count(token);
        } else {
            self.increment_ham_count(token);
        }
    }

    fn increment_spam_count(&mut self, token: &str) {
        *self.token_spam_counts.get_mut(token).unwrap() += 1;
    }

    fn increment_ham_count(&mut self, token: &str) {
        *self.token_ham_counts.get_mut(token).unwrap() += 1;
    }
}
```



è¯·æ³¨æ„ï¼Œåœ¨ HashMap ä¸­å¢åŠ ä¸€ä¸ªå€¼æ˜¯éå¸¸è€—æ—¶çš„ã€‚æ–°æ‰‹ Rust ç¨‹åºå‘˜å¾ˆéš¾ç†è§£ä¸‹é¢è¿™è¡Œä»£ç åœ¨åšä»€ä¹ˆï¼š

```rust
*self.token_spam_counts.get_mut(token).unwrap() += 1
```



ä¸ºäº†ä½¿ä»£ç æ›´æ˜ç¡®ï¼Œæˆ‘åˆ›å»ºäº† `increment_spam_count` å’Œ `increment_ham_count` å‡½æ•°ã€‚ä½†æˆ‘å¯¹æ­¤å¹¶ä¸æ»¡æ„â€”â€”è¿™ä»ç„¶å¾ˆéº»çƒ¦ã€‚å¦‚æœæ‚¨å¯¹æ›´å¥½çš„æ–¹æ³•æœ‰å»ºè®®ï¼Œè¯·ä¸æˆ‘è”ç³»ã€‚



## å¦‚ä½•ä½¿ç”¨åˆ†ç±»å™¨åšé¢„æµ‹



`predict` æ–¹æ³•æ¥æ‰‹ä¸€ä¸ªå­—ç¬¦ä¸²åˆ‡ç‰‡ï¼Œè¿”å›æ¨¡å‹å¯¹äºè¯¥æ¶ˆæ¯æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶çš„é¢„æµ‹ç»“æœã€‚



æˆ‘ä»¬åˆ›å»ºä¸¤ä¸ªè¾…åŠ©å‡½æ•° `probabilities_of_message` å’Œ `robabilites_of_token` æ¥å®Œæˆ `predict` çš„ä»»åŠ¡ã€‚



`probabilities_of_message` returnsÂ *P(Message|Spam)*Â andÂ *P(Message|ham)*



`probabilities_of_token` returnsÂ *P(Token|Spam)*Â andÂ *P(Token|ham)*



è®¡ç®—è¾“å…¥æ¶ˆæ¯æ˜¯åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡éœ€è¦å°†æ¯ä¸ªå•è¯åœ¨åƒåœ¾é‚®ä»¶ä¸­å‡ºç°çš„æ¦‚ç‡ç›¸ä¹˜ã€‚



æ¦‚ç‡æ˜¯ä»‹äº 0 å’Œ 1 ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œå°†è®¸å¤šæ¦‚ç‡ç›¸ä¹˜ä¼šå¯¼è‡´ä¸‹æº¢ï¼ˆ[å‚è€ƒ](https://learning.oreilly.com/library/view/data-science-from/9781492041122/)ï¼‰ã€‚è¿™æ˜¯å› ä¸ºå½“è®¡ç®—äº§ç”Ÿçš„æ•°å­—å°äºè®¡ç®—æœºå¯ä»¥å‡†ç¡®å­˜å‚¨çš„æ•°å­—ï¼ˆè¯·å‚é˜…[è¿™é‡Œ](https://www.techopedia.com/definition/712/underflow)å’Œ[è¿™é‡Œ](https://www.amazon.ca/Numerical-Analysis-Richard-Burden/dp/1305253663/ref=asc_df_1305253663/?tag=googleshopc0c-20&linkCode=df0&hvadid=293014842916&hvpos=&hvnetw=g&hvrand=9862733826869340686&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9001551&hvtargid=pla-450666638521&psc=1)ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¯¹æ•°å’ŒæŒ‡æ•°å°†ä»»åŠ¡è½¬æ¢ä¸ºä¸€ç³»åˆ—åŠ æ³•ï¼š

$$
\Pi_{i=0}^{n} p_{i}=\exp \left(\sum_{i=0}^{n} \log \left(p_{i}\right)\right)
$$



å› ä¸ºå¯¹äºä»»ä½•å®æ•° a å’Œ bï¼Œ
$$
ab = exp(log(ab))=exp(log(a)+log(b))
$$



æˆ‘å°†å†æ¬¡å…ˆç»™å‡º `predict` æ–¹æ³•çš„ä¼ªä»£ç ï¼š

```rust
implementation block for NaiveBayesCalssifier {
	/*...*/

	predict(self, text) {
		lower_case_text = to_lowercase(text)
		message_tokens = tokenize(text)
		(prob_if_spam, prob_if_ham) = self.probabilities_of_message(message_tokens)
		return prob_if_spam / (prob_if_spam + prob_if_ham)
	}
	
	probabilities_of_message(self, message_tokens) {
		log_prob_if_spam = 0
		log_prob_if_ham = 0

		for each token in self.tokens {
			(prob_if_spam, prob_if_ham) = self.probabilites_of_token(token)

			if message_tokens contains token {
				log_prob_if_spam = log_prob_if_spam + ln(prob_if_spam)
				log_prob_if_ham = log_prob_if_ham + ln(prob_if_ham)
			} else {
				log_prob_if_spam = log_prob_if_spam + ln(1 - prob_if_spam)
				log_prob_if_ham = log_prob_if_ham + ln(1 - prob_if_ham)
			}
		}

		prob_if_spam = exp(log_prob_if_spam)
		prob_if_ham = exp(log_prob_if_ham)

		return (prob_if_spam, prob_if_ham)
	}

	probabilites_of_token(self, token) {
		prob_of_token_spam = (self.token_spam_counts[token] + self.alpha) 
						/ (self.spam_messages_count + 2 * self.alpha)
        
		prob_of_token_ham = (self.token_ham_counts[token] + self.alpha) 
						/ (self.ham_messages_count + 2 * self.alpha)

		return (prob_of_token_spam, prob_of_token_ham)
	}
	
	
}
```



Rust çš„å…·ä½“å®ç°ï¼š

```rust
impl NaiveBayesClassifier {

		/*...*/

	pub fn predict(&self, text: &str) -> f64 {
        let lower_case_text = text.to_lowercase();
        let message_tokens = tokenize(&lower_case_text);
        let (prob_if_spam, prob_if_ham) = self.probabilities_of_message(message_tokens);

        return prob_if_spam / (prob_if_spam + prob_if_ham);
    }

    fn probabilities_of_message(&self, message_tokens: HashSet<&str>) -> (f64, f64) {
        let mut log_prob_if_spam = 0.;
        let mut log_prob_if_ham = 0.;

        for token in self.tokens.iter() {
            let (prob_if_spam, prob_if_ham) = self.probabilites_of_token(&token);

            if message_tokens.contains(token.as_str()) {
                log_prob_if_spam += prob_if_spam.ln();
                log_prob_if_ham += prob_if_ham.ln();
            } else {
                log_prob_if_spam += (1. - prob_if_spam).ln();
                log_prob_if_ham += (1. - prob_if_ham).ln();
            }
        }

        let prob_if_spam = log_prob_if_spam.exp();
        let prob_if_ham = log_prob_if_ham.exp();

        return (prob_if_spam, prob_if_ham);
    }

    fn probabilites_of_token(&self, token: &str) -> (f64, f64) {
        let prob_of_token_spam = (self.token_spam_counts[token] as f64 + self.alpha)
            / (self.spam_messages_count as f64 + 2. * self.alpha);

        let prob_of_token_ham = (self.token_ham_counts[token] as f64 + self.alpha)
            / (self.ham_messages_count as f64 + 2. * self.alpha);

        return (prob_of_token_spam, prob_of_token_ham);
    }
}
```



## å¦‚ä½•æµ‹è¯•åˆ†ç±»å™¨



è®©æˆ‘ä»¬å¯¹æ¨¡å‹åšä¸ªæµ‹è¯•ã€‚ä¸‹é¢çš„ä»£ç ä¸­çš„æ ·ä¾‹æ‰‹åŠ¨æ‰“ä¸Šäº†åˆ†ç±»æ ‡ç­¾ï¼Œç„¶åæ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹æ˜¯å¦ç»™å‡ºäº†ç›¸åŒçš„ç»“æœã€‚



æ£€æŸ¥ä»£ç é€»è¾‘æ˜¯å¾ˆæœ‰å¿…è¦çš„ï¼Œä½ å¯ä»¥å°†ä»£ç ç²˜è´´åˆ° `lib.rs` æ–‡ä»¶çš„åº•éƒ¨ä»¥æ£€æŸ¥ä½ çš„ä»£ç æ˜¯å¦æœ‰æ•ˆã€‚

```rust
// ...lib.rs

pub fn new_classifier(alpha: f64) -> NaiveBayesClassifier {
    return NaiveBayesClassifier {
        alpha,
        tokens: HashSet::new(),
        token_ham_counts: HashMap::new(),
        token_spam_counts: HashMap::new(),
        spam_messages_count: 0,
        ham_messages_count: 0,
    };
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn naive_bayes() {
        let train_messages = [
            Message {
                text: "Free Bitcoin viagra XXX christmas deals ğŸ˜»ğŸ˜»ğŸ˜»",
                is_spam: true,
            },
            Message {
                text: "My dear Granddaughter, please explain Bitcoin over Christmas dinner",
                is_spam: false,
            },
            Message {
                text: "Here in my garage...",
                is_spam: true,
            },
        ];

        let alpha = 1.;
        let num_spam_messages = 2.;
        let num_ham_messages = 1.;

        let mut model = new_classifier(alpha);
        model.train(&train_messages);

        let mut expected_tokens: HashSet<String> = HashSet::new();
        for message in train_messages.iter() {
            for token in tokenize(&message.text.to_lowercase()) {
                expected_tokens.insert(token.to_string());
            }
        }

        let input_text = "Bitcoin crypto academy Christmas deals";

        let probs_if_spam = [
            1. - (1. + alpha) / (num_spam_messages + 2. * alpha), // "Free"  (not present)
            (1. + alpha) / (num_spam_messages + 2. * alpha),      // "Bitcoin"  (present)
            1. - (1. + alpha) / (num_spam_messages + 2. * alpha), // "viagra"  (not present)
            1. - (1. + alpha) / (num_spam_messages + 2. * alpha), // "XXX"  (not present)
            (1. + alpha) / (num_spam_messages + 2. * alpha),      // "christmas"  (present)
            (1. + alpha) / (num_spam_messages + 2. * alpha),      // "deals"  (present)
            1. - (1. + alpha) / (num_spam_messages + 2. * alpha), // "my"  (not present)
            1. - (0. + alpha) / (num_spam_messages + 2. * alpha), // "dear"  (not present)
            1. - (0. + alpha) / (num_spam_messages + 2. * alpha), // "granddaughter"  (not present)
            1. - (0. + alpha) / (num_spam_messages + 2. * alpha), // "please"  (not present)
            1. - (0. + alpha) / (num_spam_messages + 2. * alpha), // "explain"  (not present)
            1. - (0. + alpha) / (num_spam_messages + 2. * alpha), // "over"  (not present)
            1. - (0. + alpha) / (num_spam_messages + 2. * alpha), // "dinner"  (not present)
            1. - (1. + alpha) / (num_spam_messages + 2. * alpha), // "here"  (not present)
            1. - (1. + alpha) / (num_spam_messages + 2. * alpha), // "in"  (not present)
            1. - (1. + alpha) / (num_spam_messages + 2. * alpha), // "garage"  (not present)
        ];

        let probs_if_ham = [
            1. - (0. + alpha) / (num_ham_messages + 2. * alpha), // "Free"  (not present)
            (1. + alpha) / (num_ham_messages + 2. * alpha),      // "Bitcoin"  (present)
            1. - (0. + alpha) / (num_ham_messages + 2. * alpha), // "viagra"  (not present)
            1. - (0. + alpha) / (num_ham_messages + 2. * alpha), // "XXX"  (not present)
            (1. + alpha) / (num_ham_messages + 2. * alpha),      // "christmas"  (present)
            (0. + alpha) / (num_ham_messages + 2. * alpha),      // "deals"  (present)
            1. - (1. + alpha) / (num_ham_messages + 2. * alpha), // "my"  (not present)
            1. - (1. + alpha) / (num_ham_messages + 2. * alpha), // "dear"  (not present)
            1. - (1. + alpha) / (num_ham_messages + 2. * alpha), // "granddaughter"  (not present)
            1. - (1. + alpha) / (num_ham_messages + 2. * alpha), // "please"  (not present)
            1. - (1. + alpha) / (num_ham_messages + 2. * alpha), // "explain"  (not present)
            1. - (1. + alpha) / (num_ham_messages + 2. * alpha), // "over"  (not present)
            1. - (1. + alpha) / (num_ham_messages + 2. * alpha), // "dinner"  (not present)
            1. - (0. + alpha) / (num_ham_messages + 2. * alpha), // "here"  (not present)
            1. - (0. + alpha) / (num_ham_messages + 2. * alpha), // "in"  (not present)
            1. - (0. + alpha) / (num_ham_messages + 2. * alpha), // "garage"  (not present)
        ];

        let p_if_spam_log: f64 = probs_if_spam.iter().map(|p| p.ln()).sum();
        let p_if_spam = p_if_spam_log.exp();

        let p_if_ham_log: f64 = probs_if_ham.iter().map(|p| p.ln()).sum();
        let p_if_ham = p_if_ham_log.exp();

        // P(message | spam) / (P(messge | spam) + P(message | ham)) rounds to 0.97
        assert!((model.predict(input_text) - p_if_spam / (p_if_spam + p_if_ham)).abs() < 0.000001);
    }
}
```



ç°åœ¨å¯ä»¥é€šè¿‡ cargo test è¿›è¡Œæµ‹è¯•ï¼Œå¦‚æœä½ æˆåŠŸé€šè¿‡äº†æµ‹è¯•ï¼Œä½ ç”¨ Rust å®ç°çš„æœ´ç´ è´å¶æ–¯æ¨¡å‹æ²¡æœ‰é—®é¢˜äº†ï¼



æ„Ÿè°¢ä½ çœ‹åˆ°è¿™é‡Œã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·éšæ—¶ä¸æˆ‘ä»¬è”ç³»ã€‚



## **References**

1. [Grus, J. (2019).Â *Data Science from Scratch: First Principles with Python, 2nd edition.*Â Oâ€™Reilly Media.](https://learning.oreilly.com/library/view/data-science-from/9781492041122/)
2. [Downey, A. (2021).Â *Think Bayes: Bayesian Statistics in Python, 2nd edition.*Â Oâ€™Reilly Media.](https://greenteapress.com/wp/think-bayes/)
3. [Murphy, K. (2012).Â *Machine Learning: A Probabilistic Perspective.*Â MIT Press.](https://probml.github.io/pml-book/book0.html)
4. [Dhinakaran, V. (2017).Â *Rust Cookbook.*Â Packt.](https://rust-lang-nursery.github.io/rust-cookbook/text/regex.html)
5. [Ng, A. (2018).Â *Stanford CS229: Lecture 5 - GDA & Naive Bayes.*](https://www.youtube.com/watch?v=nt63k3bfXS0)
6. [Burden, R. Faires, J. Burden, A. (2015).Â *Numerical Analysis, 10th edition.*Â Brooks Cole.](https://www.amazon.ca/Numerical-Analysis-Richard-Burden/dp/1305253663/ref=asc_df_1305253663/?tag=googleshopc0c-20&linkCode=df0&hvadid=293014842916&hvpos=&hvnetw=g&hvrand=9862733826869340686&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9001551&hvtargid=pla-450666638521&psc=1)
7. *[Underflow.*Â Technopedia.](https://www.techopedia.com/definition/712/underflow)